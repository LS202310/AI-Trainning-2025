yolov8 train 日志
1.在wsl2下 ubuntu22.04
      # 创建虚拟环境（推荐）
      conda create -n yolov8 python=3.8
      conda activate yolov8
      
      # 安装 PyTorch 和 Ultralytics
      pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
      pip install ultralytics

  验证 GPU 可用性
  import torch
  print(torch.cuda.is_available())  # 应输出 True
  print(torch.cuda.get_device_name(0))  # 应显示 "RTX 4050 Laptop GPU"
训练命令示例  ----但是数据来自哪里？？？

  yolo train model=yolov8s-obb.yaml data=your_dataset.yaml epochs=100 imgsz=640 batch=4 amp=True

2.注意上面 ubuntu里，使用conda env list
  base                 * /home/ls/miniconda3
  yolov8                 /home/ls/miniconda3/envs/yolov8

   conda activate yolov8
   工作目录：
   /home/ls/yolo_dir/LSB_data

3.pip show ultralytics

  ultralytics 包会被安装到 Python 的 site-packages 目录下。具体路径取决于你的 Python 环境（系统 Python、虚拟环境或 Conda 环境）。
  常见路径
  系统 Python：
  /usr/local/lib/python3.X/site-packages/
  
  Conda 虚拟环境：
  ~/miniconda3/envs/环境名/lib/python3.X/site-packages/

  which yolo

  pip uninstall ultralytics

  版本号 8.x.x 的含义
      8.3.167 表示 YOLOv8 的版本，但 PyPI 上的包名仍然是 ultralytics。
      
      这是 Ultralytics 的版本管理方式：
      
      ultralytics >= 8.0.0 对应 YOLOv8。
      
      ultralytics < 8.0.0 对应 YOLOv5（旧版）
   

    ultralytics 包会根据版本号自动提供 YOLOv8 功能：
    
    pip install ultralytics==8.x.x → YOLOv8（最新版）
    
    pip install ultralytics==5.x.x → YOLOv5（旧版）

4.pip show ultralytics
  如果 Version 是 8.x.x，说明是 YOLOv8。

  yolo detect predict model=yolov8n.pt source='https://ultralytics.com/images/bus.jpg'

 在 Ubuntu 系统中，yolov8n.pt（YOLOv8 Nano 预训练模型）默认不会自动下载，而是会在你 首次运行 YOLOv8 检测或训练时自动下载。
  手动下载模型：
  wget https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt
5.YOLOv8 OBB（Oriented Bounding Boxes）
  通过 ultralytics 自动下载：
  运行以下命令，YOLOv8 会自动下载 OBB 模型（如 yolov8n-obb.pt）到缓存目录：

    bash
    yolo detect obb predict model=yolov8n-obb.pt source='https://ultralytics.com/images/bus.jpg'

  但是这里面的东西只有15样东西，没有我需要的。

  手动下载 OBB 模型：
    wget https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n-obb.pt

    其他可用 OBB 模型：

      yolov8s-obb.pt（小模型）
      
      yolov8m-obb.pt（中模型）
      
      yolov8l-obb.pt（大模型）
      
      yolov8x-obb.pt（超大模型）

    存放自定义路径
    yolo detect obb predict model=~/models/yolov8n-obb.pt source='bus.jpg'

6.使用 OBB 模型训练/推理
    预测（推理）
    yolo detect obb predict model=yolov8n-obb.pt source='image.jpg'

    训练自定义 OBB 数据

    yolo detect obb train data=your_dataset.yaml model=yolov8n-obb.pt epochs=100
    需要准备 OBB 格式的标注文件（如 DOTA 格式的 txt 或 JSON）。

7.目前公开的 日常家电旋转框（OBB）数据集 较少，大多数 OBB 数据集集中在 航拍图像（如 DOTA）、遥感或文本检测 领域。不过，你可以通过以下方式获取或构建适用于家电的 OBB 数据：
====================================================================================================================  
        1. 现有数据集（需筛选或转换）
          (1) 通用目标检测数据集（可转 OBB）
          COCO (链接)
          
          包含家电类别（如电视、冰箱、微波炉等），但需 从水平框（HBB）转旋转框（OBB）。
          
          工具：labelme、roLabelImg 或自定义脚本转换。
          
          OpenImages (链接)
          
          部分家电类别，同样需转换标注格式。
          
          (2) 家具/室内场景数据集
          HomeObjects (GitHub)
          
          包含家电和家具的实例分割数据，可提取边界框并计算旋转角度。
          
          AI Challenger 家居检测 (链接)
          
          中文数据集，含家电类别，需手动标注旋转框。
          
          2. 手动标注工具
          若没有现成数据，可用以下工具标注 旋转框：
          
          LabelImg-Rotated (GitHub)
          
          支持 OBB 标注，输出 XML 或 TXT（DOTA 格式）。
          
          CVAT (链接)
          
          在线标注工具，支持旋转框，导出 COCO 或 VOC 格式。
          
          LabelMe (GitHub)
          
          通过多边形标注后，转换为 OBB（需后处理）。
          
          3. 数据格式转换
          若已有水平框数据，可通过以下方式生成 OBB：
          
          (1) 从分割掩码计算旋转框
          python
          from skimage.measure import find_contours
          import cv2
          import numpy as np
          
          mask = np.array(...)  # 你的分割掩码
          contours = find_contours(mask, 0.5)
          rect = cv2.minAreaRect(contours[0])  # 获取最小外接旋转矩形
          box = cv2.boxPoints(rect)            # 4个角点坐标
          (2) 水平框转旋转框
          假设水平框为 [x1, y1, x2, y2]，可手动添加旋转角度（如 0°）：
          
          txt
          # DOTA 格式（x1, y1, x2, y2, x3, y3, x4, y4, class_name, difficult）
          100 200 150 200 150 250 100 250 microwave 0
          4. 公开家电数据示例
          (1) 家电水平框数据（需转 OBB）
          Household Objects Dataset (链接)
          
          包含 120 类家电/家具的水平框标注（COCO 格式）。
          
          HomeBricks (GitHub)
          
          家具和家电的 RGB-D 数据，可提取 2D 旋转框。
          
          (2) 合成数据
          使用 Blender 或 Unity Perception 生成虚拟家电的旋转框数据。
          
          5. 训练 YOLOv8 OBB 的标注格式
          Ultralytics YOLOv8 OBB 支持 DOTA 格式（每行 9 个值）：
          
          txt
          # <class> <x1> <y1> <x2> <y2> <x3> <y3> <x4> <y4>
          tv 100 200 150 200 150 250 100 250
          fridge 300 400 400 400 400 500 300 500
          需在 dataset.yaml 中指定路径：
          
          yaml
          path: /path/to/data
          train: images/train
          val: images/val
          names:
            0: tv
            1: fridge
          总结
          方法	适用场景	工具/链接
          现有数据集转换	已有水平框数据	COCO/OpenImages → roLabelImg 或自定义脚本
          手动标注	从零开始构建数据	LabelImg-Rotated、CVAT、LabelMe
          合成数据	缺乏真实数据时	Blender、Unity Perception
          公开家电数据	快速启动（需格式转换）	Household Objects Dataset、HomeBricks
          建议步骤：
          
          从 Household Objects Dataset 或 COCO 筛选家电类别。
          
          用 roLabelImg 标注旋转框，或从水平框生成 OBB。
          
          按 DOTA 格式组织数据，训练 YOLOv8 OBB。
          
          如果需要具体代码示例（如格式转换），可以告诉我你的数据来源，我会提供详细脚本！
====================================================================================================================
8.从Household Objects Dataset 或COCO 只选择tv类别，进行转换，并作为yolov8 obb的训练数据
  以下是 从COCO或Household Objects Dataset中提取TV类别并转换为YOLOv8 OBB格式 的完整步骤，包含代码示例和详细说明：
  ------------------------------------------------------------------------------------------------------------
  重点！！！！
      1. 数据准备（以COCO为例）
      (1) 下载COCO数据集
      下载 COCO 2017 中的 train2017.zip 和 annotations_trainval2017.zip：
      
      bash
      wget http://images.cocodataset.org/zips/train2017.zip
      wget http://images.cocodataset.org/annotations/annotations_trainval2017.zip
      unzip train2017.zip
      unzip annotations_trainval2017.zip
      (2) 确认TV类别的ID
      COCO中TV的类别名称为 "tv" 或 "television"，对应 category_id=72（可通过 annotations/instances_train2017.json 查看）。
      
      2. 提取TV类别并转OBB格式
      (1) 安装依赖
      bash
      pip install pycocotools numpy opencv-python
      (2) 提取TV标注并计算旋转框
      python
      import json
      import cv2
      import numpy as np
      from pycocotools.coco import COCO
      import os
      
      # 初始化COCO API
      coco = COCO('annotations/instances_train2017.json')
      
      # 获取TV类别的所有标注
      cat_ids = coco.getCatIds(catNms=['tv'])
      img_ids = coco.getImgIds(catIds=cat_ids)
      annotations = coco.loadAnns(coco.getAnnIds(imgIds=img_ids, catIds=cat_ids))
      
      # 创建输出目录
      os.makedirs('tv_obb/labels', exist_ok=True)
      os.makedirs('tv_obb/images', exist_ok=True)
      
      # 遍历标注，生成OBB格式（DOTA风格）
      for ann in annotations:
          if 'segmentation' not in ann:
              continue
              
          # 获取图像信息
          img = coco.loadImgs(ann['image_id'])[0]
          img_path = f'train2017/{img["file_name"]}'
          
          # 从分割掩码计算旋转框
          mask = coco.annToMask(ann)
          contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
          if not contours:
              continue
              
          # 取最大轮廓的最小外接旋转矩形
          rect = cv2.minAreaRect(contours[0])
          box = cv2.boxPoints(rect)  # 获取4个角点坐标
          
          # 归一化到图像尺寸
          box = box / np.array([img['width'], img['height']])
          box = box.flatten().tolist()
          
          # 写入OBB标签文件（DOTA格式）
          label_path = f'tv_obb/labels/{img["file_name"].replace(".jpg", ".txt")}'
          with open(label_path, 'a') as f:
              f.write(f'tv {" ".join(map(str, box))}\n')
          
          # 复制图像到输出目录
          os.system(f'cp {img_path} tv_obb/images/')
      3. 转换为YOLOv8 OBB格式
      YOLOv8 OBB需要 DOTA格式 的标注文件（每行8个坐标+类别），但需调整目录结构：
      
      (1) 最终目录结构
      text
      tv_obb/
      ├── images/
      │   ├── 0000001.jpg
      │   └── ...
      └── labels/
          ├── 0000001.txt  # 内容示例：tv 0.1 0.2 0.3 0.2 0.3 0.4 0.1 0.4
          └── ...
      (2) 创建数据集YAML文件
      yaml
      # tv_obb.yaml
      path: /path/to/tv_obb
      train: images
      val: images  # 若无验证集，暂用训练集
      names:
        0: tv
      4. 训练YOLOv8 OBB模型
      bash
      yolo detect obb train data=tv_obb.yaml model=yolov8n-obb.pt epochs=50 imgsz=640

------------------------------------------------------------------------------------------------------------

    上面旋转框的旋转可以优化。
                      您提供的旋转框转换代码整体逻辑是正确的，但存在几个需要特别注意的关键点。以下是对代码的详细分析及改进建议：
                  
                        1. 关键问题检查
                        (1) 轮廓处理风险
                        python
                        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                        rect = cv2.minAreaRect(contours[0])  # 直接取第一个轮廓
                        问题：若分割掩码存在多个不连通区域，可能遗漏主物体
                        
                        改进：选择面积最大的轮廓
                        
                        python
                        contours = sorted(contours, key=cv2.contourArea, reverse=True)
                        if contours:
                            rect = cv2.minAreaRect(contours[0])
                        (2) 归一化顺序问题
                        python
                        box = box / np.array([img['width'], img['height']])
                        问题：坐标点未按规范排序（DOTA格式要求顺时针/逆时针顺序）
                        
                        改进：添加坐标排序
                        
                        python
                        from scipy.spatial import ConvexHull
                        hull = ConvexHull(box)
                        box = box[hull.vertices]  # 按凸包顶点排序
                        (3) 多物体处理
                        当前代码会追加写入('a'模式)，若图像有多个TV实例会导致标签文件多行
                        
                        建议：改为覆盖写入('w')，或确保每图像只处理一个实例
                        
                        2. 改进后的完整代码
                        python
                        import json
                        import cv2
                        import numpy as np
                        from pycocotools.coco import COCO
                        from scipy.spatial import ConvexHull
                        import os
                        
                        # 初始化COCO API
                        coco = COCO('annotations/instances_train2017.json')
                        
                        # 获取TV类别的所有标注
                        cat_ids = coco.getCatIds(catNms=['tv', 'television'])  # 覆盖两种命名
                        img_ids = coco.getImgIds(catIds=cat_ids)
                        annotations = coco.loadAnns(coco.getAnnIds(imgIds=img_ids, catIds=cat_ids))
                        
                        # 创建输出目录
                        os.makedirs('tv_obb/labels', exist_ok=True)
                        os.makedirs('tv_obb/images', exist_ok=True)
                        
                        for ann in annotations:
                            if 'segmentation' not in ann or not ann['segmentation']:
                                continue
                                
                            # 获取图像信息
                            img = coco.loadImgs(ann['image_id'])[0]
                            img_path = f'train2017/{img["file_name"]}'
                            label_path = f'tv_obb/labels/{img["file_name"].replace(".jpg", ".txt")}'
                            
                            # 生成掩码并找轮廓
                            mask = coco.annToMask(ann)
                            contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                            if not contours:
                                continue
                            
                            # 取面积最大的轮廓
                            contours = sorted(contours, key=cv2.contourArea, reverse=True)
                            rect = cv2.minAreaRect(contours[0])
                            box = cv2.boxPoints(rect)
                            
                            # 坐标排序（顺时针）
                            hull = ConvexHull(box)
                            box = box[hull.vertices]
                            
                            # 归一化并保存
                            box = box / np.array([img['width'], img['height']])
                            with open(label_path, 'w') as f:  # 改为覆盖写入
                                f.write(f'0 {" ".join(map(str, box.flatten().round(6)))}\n')  # 使用类别ID
                                
                            # 复制图像（如果尚未复制）
                            if not os.path.exists(f'tv_obb/images/{img["file_name"]}'):
                                os.system(f'cp {img_path} tv_obb/images/')
                        3. 关键改进说明
                        改进点	原代码问题	现解决方案
                        轮廓选择	可能选中次要轮廓	按面积排序取最大轮廓
                        坐标顺序	未保证顺时针/逆时针	用凸包(ConvexHull)排序
                        类别标识	使用'tv'字符串	改用数字0（需与yaml文件一致）
                        文件写入	追加模式可能导致多行标签	覆盖写入保证单图像单标签文件
                        归一化精度	浮点数精度过高	限制为6位小数
                        4. 验证方法
                        (1) 可视化检查
                        python
                        import matplotlib.pyplot as plt
                        
                        def plot_obb(img_path, label_path):
                            img = cv2.imread(img_path)
                            h, w = img.shape[:2]
                            
                            with open(label_path) as f:
                                line = f.readline()
                                parts = list(map(float, line.strip().split()[1:]))
                                box = np.array(parts).reshape(-1, 2) * [w, h]
                            
                            cv2.polylines(img, [box.astype(int)], True, (0,255,0), 2)
                            plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
                            plt.show()
                        
                        # 示例检查
                        sample_img = "tv_obb/images/000000581637.jpg"
                        sample_label = "tv_obb/labels/000000581637.txt"
                        plot_obb(sample_img, sample_label)
                        (2) 格式验证
                        检查生成的标签文件是否符合：
                        
                        text
                        0 x1 y1 x2 y2 x3 y3 x4 y4
                        所有坐标值应在[0,1]范围内
                        
                        四个点应按顺时针或逆时针排列
                        
                        5. 常见问题处理
                        旋转框角度异常
                        
                        检查cv2.minAreaRect()返回的角度是否在[-90,0]范围内
                        
                        可添加角度修正逻辑：
                        
                        python
                        if rect[2] < -45:
                            rect = (rect[0], (rect[1][1], rect[1][0]), rect[2]+90)
                        多物体处理
                        
                        如需处理单图多实例，改为：
                        
                        python
                        with open(label_path, 'a') as f:  # 追加模式
                            for contour in contours[:5]:  # 最多处理前5个实例
                                rect = cv2.minAreaRect(contour)
                                # ...后续处理...
                        COCO标注类型
                        
                        某些COCO标注可能是RLE格式而非多边形，需特殊处理：
                        
                        python
                        if type(ann['segmentation']) == list:
                            # 多边形处理
                        else:
                            # RLE转mask需用pycocotools的decode
                            mask = coco.annToMask(ann)
                        建议在实际应用前，先用少量样本（如10张图）验证转换结果的正确性。

------------------------------------------------------------------------------------------------------------

9.如果出现格式问题，检查：
  检查数据集YAML文件
确保您的 tv_obb.yaml 包含正确的类别映射：

yaml
path: /home/ls/yolo_dir/LSB_data/tv_obb
train: images
val: images  # 如果没有单独的验证集
names:
  0: tv  # 确保与标签文件中的类别名一致

  ----------------------------------------------
更新YAML配置文件
确保 tv_obb.yaml 严格匹配：

yaml
path: /home/ls/yolo_dir/LSB_data/tv_obb
train: images
val: images  # 如果无验证集，使用训练集
names: 
  0: tv  # 必须与标签中的class_id对应
obb_format: xyxyxyxy  # 显式声明OBB格式


